#!/bin/bash

#SBATCH --partition=gpu
#SBATCH --gpus=1
#SBATCH --job-name=RunEval_en_cs
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=18
#SBATCH --time=04:00:00
#SBATCH --output=/home/scur1772/ALMA-Matters/utils/script_outputs/RunEval_en_cs_%A.out

# Load necessary modules
module purge
module load 2023
module load Python/3.11.3-GCCcore-12.3.0  # Load the Python 3.11.3 module
module load PyTorch/2.1.2-foss-2023a-CUDA-12.1.1  # Load PyTorch with CUDA support

# Install missing dependencies locally
pip install --user tqdm transformers datasets sentencepiece accelerate peft halo ml_collections sacrebleu comet

# Set directories and test pairs
OUTPUT_DIR="$HOME/ALMA-Matters/evaluation/results/baseline"
TEST_PAIRS="en-cs"  # Define language pairs as needed

# Define true translations path (if different from evaluation)
TRUE_TRANSLATIONS_DIR="$HOME/ALMA-Matters/datasets/human-translations"

# Define tokenization logic for BLEU and run COMET evaluations
for pair in ${TEST_PAIRS//,/ }; do
    src=$(echo ${pair} | cut -d "-" -f 1)
    tgt=$(echo ${pair} | cut -d "-" -f 2)

    # Set tokenization logic
    TOK="13a"
    if [ ${tgt} == "zh" ]; then
        TOK="zh"
    elif [ ${tgt} == "ja" ]; then
        TOK="ja-mecab"
    fi

    echo "--------------------Results for ${pair}-------------------------------------"

    # Set paths for source, target, and output
    src_path=${TRUE_TRANSLATIONS_DIR}/ALMA_test_${src}-${tgt}.json
    tgt_path=${TRUE_TRANSLATIONS_DIR}/ALMA_test_${src}-${tgt}.json
    output_path=${OUTPUT_DIR}/result_${src}-${tgt}.txt

    # BLEU evaluation
    SACREBLEU_FORMAT=text sacrebleu -tok ${TOK} -w 2 ${tgt_path} < ${output_path} > ${output_path}.bleu
    cat ${output_path}.bleu

    # COMET evaluation (using different models)
    comet-score -s ${src_path} -t ${output_path} -r ${tgt_path} --batch_size 256 --model Unbabel/wmt22-comet-da --gpus 1 > ${output_path}.comet
    comet-score -s ${src_path} -t ${output_path} --batch_size 256 --model Unbabel/wmt22-cometkiwi-da --gpus 1 > ${output_path}.cometkiwi
    comet-score -s ${src_path} -t ${output_path} --batch_size 8 --model Unbabel/wmt23-cometkiwi-da-xxl --gpus 1 > ${output_path}.cometkiwi_10b
    comet-score -s ${src_path} -t ${output_path} --batch_size 8 --model Unbabel/XCOMET-XXL --gpus 1 --to_json ${output_path}.xcomet.output.json > ${output_path}.xcomet_10b    

    # Display final results
    tail -n 1 ${output_path}.comet
done

# Print results summary
for pair in ${TEST_PAIRS//,/ }; do
    src=$(echo ${pair} | cut -d "-" -f 1)
    tgt=$(echo ${pair} | cut -d "-" -f 2)
    output_path=${OUTPUT_DIR}/result_${src}-${tgt}.txt

    echo "---------------------------${src}-${tgt}-------------------------------"
    cat ${output_path}.bleu
    tail -n 1 ${output_path}.comet
    tail -n 1 ${output_path}.cometkiwi
    tail -n 1 ${output_path}.cometkiwi_10b
    tail -n 2 ${output_path}.xcomet_10b
done
