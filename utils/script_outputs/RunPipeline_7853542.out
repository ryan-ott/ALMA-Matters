============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]Downloading shards:  33%|███▎      | 1/3 [07:42<15:24, 462.20s/it]Downloading shards:  67%|██████▋   | 2/3 [28:43<15:32, 932.19s/it]Downloading shards: 100%|██████████| 3/3 [31:46<00:00, 590.19s/it]Downloading shards: 100%|██████████| 3/3 [31:46<00:00, 635.53s/it]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:05<00:10,  5.08s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:09<00:04,  4.45s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.70s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:11<00:00,  3.97s/it]
Traceback (most recent call last):
  File "/gpfs/home4/scur1769/ALMA-Matters/run_pipeline.py", line 45, in <module>
    main()
  File "/gpfs/home4/scur1769/ALMA-Matters/run_pipeline.py", line 31, in main
    tokenizer = LlamaTokenizer.from_pretrained("haoranxu/ALMA-7B", padding_side='left')
  File "/home/scur1769/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1543, in __getattribute__
    requires_backends(cls, cls._backends)
  File "/home/scur1769/.local/lib/python3.9/site-packages/transformers/utils/import_utils.py", line 1531, in requires_backends
    raise ImportError("".join(failed))
ImportError: 
LlamaTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the
installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.


JOB STATISTICS
==============
Job ID: 7853542
Cluster: snellius
User/Group: scur1769/scur1769
State: FAILED (exit code 1)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:02:07
CPU Efficiency: 0.36% of 09:42:00 core-walltime
Job Wall-clock time: 00:32:20
Memory Utilized: 8.21 GB
Memory Efficiency: 6.84% of 120.00 GB
